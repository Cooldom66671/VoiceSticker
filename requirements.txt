# =============================================
# Core Dependencies
# =============================================
python-dotenv==1.0.1
aiofiles==23.2.1
aiohttp==3.9.5
asyncio==3.4.3
typing-extensions==4.11.0

# =============================================
# Telegram Bot Framework
# =============================================
aiogram==3.7.0
magic-filter==1.0.12
aiohttp-cors==0.7.0

# =============================================
# Database
# =============================================
aiosqlite==0.20.0
redis==5.0.1  # For production FSM storage

# =============================================
# Image Processing
# =============================================
Pillow==10.3.0
opencv-python-headless==4.9.0.80
numpy==1.26.4
scipy==1.13.0
scikit-image==0.23.2
rembg==2.0.56  # Background removal
colorthief==0.2.1  # Color extraction

# =============================================
# Audio Processing
# =============================================
pydub==0.25.1
ffmpeg-python==0.2.0
librosa==0.10.2
soundfile==0.12.1

# =============================================
# Speech Recognition (Whisper)
# =============================================
openai-whisper==20231117
tiktoken==0.6.0
more-itertools==10.2.0
numba==0.59.1  # For librosa optimization

# =============================================
# Image Generation (Stable Diffusion)
# =============================================
diffusers==0.27.2
transformers==4.40.2
accelerate==0.30.1
safetensors==0.4.3
omegaconf==2.3.0
einops==0.8.0
kornia==0.7.2  # Image transformations
xformers==0.0.26; platform_system != "Darwin"  # Not for macOS

# =============================================
# PyTorch - Choose based on your system
# =============================================
# For CPU only:
# torch==2.3.0+cpu
# torchvision==0.18.0+cpu
# torchaudio==2.3.0+cpu
# --extra-index-url https://download.pytorch.org/whl/cpu

# For CUDA 11.8:
# torch==2.3.0+cu118
# torchvision==0.18.0+cu118
# torchaudio==2.3.0+cu118
# --extra-index-url https://download.pytorch.org/whl/cu118

# For CUDA 12.1:
# torch==2.3.0
# torchvision==0.18.0
# torchaudio==2.3.0
# --index-url https://download.pytorch.org/whl/cu121

# For Apple Silicon (default):
torch==2.3.0
torchvision==0.18.0
torchaudio==2.3.0

# =============================================
# System Monitoring & Performance
# =============================================
psutil==5.9.8
py-cpuinfo==9.0.0
uvloop==0.19.0; platform_system != "Windows"  # Better event loop for Unix

# =============================================
# Utilities
# =============================================
python-json-logger==2.0.7  # Structured logging
click==8.1.7  # CLI utilities
tqdm==4.66.4  # Progress bars
humanize==4.9.0  # Human-readable formats
python-dateutil==2.9.0
pytz==2024.1

# =============================================
# Development Tools (optional)
# =============================================
pytest==8.2.1
pytest-asyncio==0.23.7
pytest-cov==5.0.0
pytest-mock==3.14.0
black==24.4.2
flake8==7.0.0
mypy==1.10.0
isort==5.13.2
pre-commit==3.7.1
ipython==8.24.0

# =============================================
# Type Checking Stubs
# =============================================
types-aiofiles==23.2.0.20240311
types-Pillow==10.2.0.20240520
types-redis==4.6.0.20240425
types-requests==2.32.0.20240523

# =============================================
# Documentation (optional)
# =============================================
sphinx==7.3.7
sphinx-rtd-theme==2.0.0
myst-parser==3.0.1

# =============================================
# Production Dependencies
# =============================================
gunicorn==22.0.0  # For webhook mode
supervisor==4.2.5  # Process management
python-multipart==0.0.9  # For file uploads
prometheus-client==0.20.0  # Metrics export
sentry-sdk==2.3.1  # Error tracking

# =============================================
# Security
# =============================================
cryptography==42.0.7
certifi==2024.2.2

# =============================================
# ML Model Optimization (optional)
# =============================================
onnx==1.16.1  # Model conversion
onnxruntime==1.18.0  # Faster inference
tensorrt==10.0.1; platform_system == "Linux" and platform_machine == "x86_64"  # NVIDIA optimization